{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "58635464-8094-4a92-b7b4-0618fb8e92fb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# This Notebook is to Experiment LangGraph Agents\n",
    "\n",
    "The Sequential Tasks are:\n",
    "- Collect Model information from MLFlow run\n",
    "- Collect the notebook information\n",
    "- Write a ML document draft\n",
    "- Review the draft and create a final version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2c6a034e-4784-46d6-96c6-ac0bd3c8e5d8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install -U -qqqq mlflow langchain langgraph==0.3.4 databricks-langchain pydantic databricks-agents unitycatalog-langchain[databricks] uv json2html markdownify\n",
    "%restart_python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-13T05:44:00.571453Z",
     "start_time": "2025-05-13T05:44:00.468935Z"
    },
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6b8de65b-bee0-4390-b392-06051717c3c0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-13T05:44:07.338659Z",
     "start_time": "2025-05-13T05:44:04.215450Z"
    },
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c2aa171e-2df5-4412-9e42-2ca2d765dae8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from databricks.connect import DatabricksSession\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import mlflow\n",
    "import warnings\n",
    "\n",
    "DATABRICKS_HOST = (\n",
    "    dbutils.notebook.entry_point.getDbutils().notebook().getContext().apiUrl().get()\n",
    ")\n",
    "DATABRICKS_TOKEN = (\n",
    "    dbutils.notebook.entry_point.getDbutils()\n",
    "    .notebook()\n",
    "    .getContext()\n",
    "    .apiToken()\n",
    "    .getOrElse(None)\n",
    ")\n",
    "os.environ[\"OPENAI_API_KEY\"] = dbutils.secrets.get(\n",
    "    scope=\"databricks_token_qyu\", key=\"OpenAi\"\n",
    ")\n",
    "mlflow.set_tracking_uri(\"databricks\")\n",
    "mlflow.set_registry_uri(\"databricks-uc\")\n",
    "mlflow.set_experiment(\n",
    "    \"/Users/q.yu@databricks.com/ML_experiments/auto_ml_document_agents\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b318d7c8-f2e4-4c62-9500-1b61564233fb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Create LangGraph Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-13T05:44:16.786310Z",
     "start_time": "2025-05-13T05:44:16.763185Z"
    },
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4b24cc37-2e9d-4368-beba-58c2f3dfbb2c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%%writefile ml_documentation_agent.py\n",
    "from typing import Any, Generator, Optional, Sequence, Union, TypedDict, Dict, List\n",
    "import mlflow\n",
    "from databricks_langchain import ChatDatabricks, VectorSearchRetrieverTool\n",
    "from databricks_langchain.uc_ai import (\n",
    "    DatabricksFunctionClient,\n",
    "    UCFunctionToolkit,\n",
    "    set_uc_function_client,\n",
    ")\n",
    "from langchain_core.language_models import LanguageModelLike\n",
    "from langchain_core.runnables import RunnableConfig, RunnableLambda\n",
    "from langchain_core.messages import HumanMessage, AIMessage, BaseMessage, SystemMessage\n",
    "from langchain_core.tools import BaseTool\n",
    "from langchain_core.documents import Document\n",
    "from langgraph.graph import END, StateGraph, START\n",
    "from langgraph.graph.graph import CompiledGraph\n",
    "from langgraph.graph.state import CompiledStateGraph\n",
    "from mlflow.langchain.chat_agent_langgraph import ChatAgentState, ChatAgentToolNode\n",
    "from mlflow.pyfunc import ChatAgent\n",
    "from mlflow.types.agent import (\n",
    "    ChatAgentChunk,\n",
    "    ChatAgentMessage,\n",
    "    ChatAgentResponse,\n",
    "    ChatContext,\n",
    ")\n",
    "from model_artifacts_organizer import ModelArtifactOrganizer\n",
    "from file_management_utils import recursive_file_loader\n",
    "\n",
    "mlflow.langchain.autolog()\n",
    "\n",
    "############################################\n",
    "# Define your LLM endpoint and system prompt\n",
    "############################################\n",
    "LLM_ENDPOINT_NAME = \"databricks-meta-llama-3-3-70b-instruct\"\n",
    "LLM = ChatDatabricks(endpoint=LLM_ENDPOINT_NAME)\n",
    "\n",
    "# Prompts\n",
    "WRITTER_PROMPT = \"\"\"\n",
    "Role and Purpose:\n",
    "You are a specialized ML Documentation Writer that transforms MLflow artifacts into comprehensive, well-structured markdown documentation. Your task is to create clear, concise, and informative documentation about machine learning models that will be used by other data scientists and model users.\n",
    "\n",
    "Input Format\n",
    "I will provide you with the following MLflow artifacts:\n",
    "\n",
    "- Model metrics (accuracy, precision, recall, etc.)\n",
    "- Model information (algorithm type, version, etc.)\n",
    "- Environment details (dependencies, packages, versions)\n",
    "- Data source information (dataset details, preprocessing steps)\n",
    "- Paths to visualization artifacts (PNG plots of metrics, predictions, etc.)\n",
    "\n",
    "Any additional relevant information about the model such as notebook codes\n",
    "\n",
    "Output Structure\n",
    "Create a markdown document with the following sections:\n",
    "\n",
    "- Model Overview\n",
    "- Model name and version\n",
    "- Brief description of the model's purpose\n",
    "- Key capabilities and use cases\n",
    "- Model Specifications\n",
    "- Algorithm type and architecture\n",
    "- Hyperparameters\n",
    "- Framework and dependencies\n",
    "- Training environment details and Training Data\n",
    "- Dataset description and source\n",
    "- Quantitative metrics (accuracy, precision, recall, F1, etc.)\n",
    "- Visualization references (link plots using relative paths)\n",
    "- Model Artifacts\n",
    "\n",
    "Formatting Guidelines:\n",
    "\n",
    "- Use level 2 headers (##) for main sections and bolding (**) for subsections\n",
    "- Include relevant code snippets in markdown code blocks with appropriate language highlighting if available\n",
    "- Embed visualization references using markdown image syntax\n",
    "- Use tables for comparing metrics or features where appropriate\n",
    "- For mathematical expressions, use LaTeX syntax with for inline and for block formulas\n",
    "- Use bullet points and numbered lists for clarity\n",
    "- Keep language clear and concise, avoiding unnecessary jargon\n",
    "\n",
    "Best Practices\n",
    "- Maintain a consistent writing style throughout the document\n",
    "- Be concise but thorough in your explanations\n",
    "- Include relevant plots and visualizations using markdown image syntax\n",
    "- Make sure plots and tables are properly described and labeled\n",
    "- Define technical terms when first introduced\n",
    "-Focus on information that helps others understand and use the model effectively\n",
    "\"\"\"\n",
    "\n",
    "REVIEWER_PROMPT = \"\"\"\n",
    "Role and Purpose:\n",
    "You are a professional proofreading expert tasked with meticulously reviewing documents and producing polished final versions. Your objective is to transform draft content into error-free, coherent, and professionally styled documents while preserving the author's original voice and intent.\n",
    "\n",
    "Review Process Instructions:\n",
    "When presented with a document, perform these comprehensive checks:\n",
    "\n",
    "- Grammatical Analysis\n",
    "- Identify and correct all grammatical mistakes\n",
    "- Ensure proper sentence structure\n",
    "- Verify correct verb tense consistency\n",
    "- Check subject-predicate agreement\n",
    "- Review pronoun usage and reference clarity\n",
    "\n",
    "Mechanical Corrections:\n",
    "\n",
    "- Fix spelling errors and typos\n",
    "- Correct punctuation issues\n",
    "- Standardize capitalization\n",
    "- Address formatting inconsistencies\n",
    "- Ensure proper citation format if applicable\n",
    "\n",
    "Content Enhancement\n",
    "\n",
    "- Improve sentence flow and transitions between paragraphs\n",
    "- Enhance clarity by simplifying complex sentences when necessary\n",
    "- Eliminate redundancies and unnecessary words\n",
    "- Strengthen weak phrasing\n",
    "- Ensure logical progression of ideas\n",
    "\n",
    "Style and Tone Assessment\n",
    "\n",
    "- Maintain consistent tone throughout\n",
    "- Unify terminology and notation\n",
    "- Ensure appropriate formality level for the document's purpose\n",
    "- Check for consistent point of view\n",
    "- Verify style guide compliance if specified\n",
    "\n",
    "Document Structure Review\n",
    "- Confirm proper formatting of headings and subheadings\n",
    "- Verify logical organization of sections\n",
    "- Check that bullet points and numbered lists follow consistent structure\n",
    "- Ensure table and figure references are accurate\n",
    "- Review overall document layout\n",
    "\n",
    "Guidelines\n",
    "- Preserve the author's original voice and meaning\n",
    "- Make only necessary changes without altering core content\n",
    "- When multiple correction options exist, choose the one that best maintains the document's original style\n",
    "- For specialized terminology or jargon, verify correctness before making changes\n",
    "- If something is ambiguous, provide alternative interpretations and recommendations\n",
    "- Ensure the final document maintains consistent formatting throughout\n",
    "- For substantive restructuring needs, highlight recommendations separately rather than implementing directly\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# Step 1\n",
    "def collect_ml_document_content(state: ChatAgentState) -> dict:\n",
    "    \"\"\"Process the content organization.\"\"\"\n",
    "    model_artifacts_organizer = ModelArtifactOrganizer(\n",
    "        catalog=state[\"custom_inputs\"][\"catalog\"],\n",
    "        schema=state[\"custom_inputs\"][\"schema\"],\n",
    "        model=state[\"custom_inputs\"][\"model\"],\n",
    "    )\n",
    "    # Collect ML model assets\n",
    "    artifact_volume_path = model_artifacts_organizer.collect_mlflow_artifacts()\n",
    "\n",
    "    # Create model attributes table, notebook, and image markdown\n",
    "    model_artifacts_organizer.create_model_attributes_md()\n",
    "    model_artifacts_organizer.notebook_to_md()\n",
    "    model_artifacts_organizer.image_file_to_md()\n",
    "\n",
    "    # Collect content source files\n",
    "    doc_contents = recursive_file_loader(artifact_volume_path)\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You are a MLops experts\"},\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Collected ML model assets, generated model \"\n",
    "            \"attributes table, notebook, and image markdown.\",\n",
    "        },\n",
    "    ]\n",
    "\n",
    "    # Create a summary of all files\n",
    "    files_content = \"\\n\\n\".join(\n",
    "        [\n",
    "            f\"\"\"File: {doc.metadata['relative_path']}\n",
    "                 File Type: {doc.metadata['file_type']}\n",
    "                 <content>\\n{doc.page_content}\\n</content>\"\"\"\n",
    "            for doc in doc_contents\n",
    "        ]\n",
    "    )\n",
    "    custom_outputs = state.get(\"custom_outputs\", {}).copy()\n",
    "    custom_outputs[\"source_contents\"] = files_content\n",
    "    state[\"custom_outputs\"] = {}\n",
    "    state[\"custom_outputs\"][\"source_contents\"] = files_content\n",
    "    messages.append({\"role\": \"assistant\", \"content\": files_content})\n",
    "\n",
    "    return {\"messages\": messages, \"custom_outputs\": custom_outputs}\n",
    "\n",
    "\n",
    "# Step 2\n",
    "def write_doc_draft(state: ChatAgentState) -> dict:\n",
    "    \"\"\"write the ml document draft\"\"\"\n",
    "\n",
    "    files_content = state.get(\"custom_outputs\", {}).get(\n",
    "        \"source_contents\", \"No content found\"\n",
    "    )\n",
    "    content_message = {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": f\"Here is the content of the files: {files_content}\",\n",
    "    }\n",
    "\n",
    "    # Generate the outline\n",
    "    messages = [{\"role\": \"system\", \"content\": WRITTER_PROMPT}] + [content_message]\n",
    "    response = LLM.invoke(messages)\n",
    "\n",
    "    custom_outputs = state.get(\"custom_outputs\", {}).copy()\n",
    "    custom_outputs[\"document_draft\"] = response.content\n",
    "    state[\"custom_outputs\"][\"document_draft\"] = response.content\n",
    "\n",
    "    return {\n",
    "        \"messages\": [{\"role\": \"assistant\", \"content\": response.content}],\n",
    "        \"custom_outputs\": custom_outputs,\n",
    "    }\n",
    "\n",
    "\n",
    "# Step 3\n",
    "def review_doc_draft(state: ChatAgentState, config: RunnableConfig) -> dict:\n",
    "    \"\"\"review the ml document draft and write the final version\"\"\"\n",
    "\n",
    "    doc_draft = state.get(\"custom_outputs\", {}).get(\n",
    "        \"document_draft\", \"No draft available\"\n",
    "    )\n",
    "    draft_message = {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": f\"Here is the draft of the ml document: {doc_draft}\",\n",
    "    }\n",
    "    # Generate the outline\n",
    "    messages = [{\"role\": \"system\", \"content\": REVIEWER_PROMPT}] + [draft_message]\n",
    "    response = LLM.invoke(messages)\n",
    "\n",
    "    custom_outputs = state.get(\"custom_outputs\", {}).copy()\n",
    "    custom_outputs[\"final_document\"] = response.content\n",
    "    state[\"custom_outputs\"][\"final_document\"] = response.content\n",
    "\n",
    "    return {\n",
    "        \"messages\": [{\"role\": \"assistant\", \"content\": response.content}],\n",
    "        \"custom_outputs\": custom_outputs,\n",
    "    }\n",
    "\n",
    "# Build a Graph\n",
    "workflow = StateGraph(ChatAgentState)\n",
    "\n",
    "# Create nodes\n",
    "workflow.add_node(\"collect_ml_document_content\", collect_ml_document_content)\n",
    "workflow.add_node(\"write_doc_draft\", RunnableLambda(write_doc_draft))\n",
    "workflow.add_node(\"review_doc_draft\", RunnableLambda(review_doc_draft))\n",
    "\n",
    "# Create edges\n",
    "workflow.set_entry_point(\"collect_ml_document_content\")\n",
    "workflow.add_edge(\"collect_ml_document_content\", \"write_doc_draft\")\n",
    "workflow.add_edge(\"write_doc_draft\", \"review_doc_draft\")\n",
    "workflow.add_edge(\"review_doc_draft\", END)\n",
    "\n",
    "auto_ml_doc_flow = workflow.compile()\n",
    "\n",
    "# wrap it at a mlflow ChatAgent to enable agent framework\n",
    "class LangGraphChatAgent(ChatAgent):\n",
    "    def __init__(self, agent: CompiledStateGraph):\n",
    "        self.agent = agent\n",
    "\n",
    "    def predict(\n",
    "        self,\n",
    "        messages: list[ChatAgentMessage],\n",
    "        context: Optional[ChatContext] = None,\n",
    "        custom_inputs: Optional[dict[str, Any]] = None,\n",
    "    ) -> ChatAgentResponse:\n",
    "        request = {\"messages\": self._convert_messages_to_dict(messages)}\n",
    "\n",
    "        if context:\n",
    "            request[\"context\"] = context\n",
    "\n",
    "        if custom_inputs:\n",
    "            request[\"custom_inputs\"] = custom_inputs\n",
    "\n",
    "        messages = []\n",
    "        custom_outputs = {}\n",
    "        for event in self.agent.stream(request, stream_mode=\"updates\"):\n",
    "            for node_data in event.values():\n",
    "                messages.extend(\n",
    "                    ChatAgentMessage(**msg) for msg in node_data.get(\"messages\", [])\n",
    "                )\n",
    "                if \"custom_outputs\" in node_data:\n",
    "                    custom_outputs.update(node_data[\"custom_outputs\"])\n",
    "\n",
    "        return ChatAgentResponse(messages=messages, custom_outputs=custom_outputs)\n",
    "\n",
    "    def predict_stream(\n",
    "        self,\n",
    "        messages: list[ChatAgentMessage],\n",
    "        context: Optional[ChatContext] = None,\n",
    "        custom_inputs: Optional[dict[str, Any]] = None,\n",
    "    ) -> Generator[ChatAgentChunk, None, None]:\n",
    "        request = {\"messages\": self._convert_messages_to_dict(messages)}\n",
    "\n",
    "        if context:\n",
    "            request[\"context\"] = context\n",
    "\n",
    "        if custom_inputs:\n",
    "            request[\"custom_inputs\"] = custom_inputs\n",
    "\n",
    "        for event in self.agent.stream(request, stream_mode=\"updates\"):\n",
    "            for node_data in event.values():\n",
    "                yield from (\n",
    "                    ChatAgentChunk(**{\"delta\": msg}) for msg in node_data[\"messages\"]\n",
    "                )\n",
    "\n",
    "AGENT = LangGraphChatAgent(auto_ml_doc_flow)\n",
    "mlflow.models.set_model(AGENT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7a397b06-85ba-4a74-9f9d-5493c1802d4f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%restart_python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-13T05:44:35.191662Z",
     "start_time": "2025-05-13T05:44:32.543167Z"
    },
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "925fd627-825e-42a6-bda7-2ba000b7aa3d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from ml_documentation_agent import AGENT\n",
    "\n",
    "# target ml model to document\n",
    "CATALOG = \"qyu\"\n",
    "SCHEMA = \"dbdemos_fs_travel\"\n",
    "model = \"dbdemos_fs_travel_model\"\n",
    "\n",
    "result = AGENT.predict(\n",
    "    {\n",
    "        \"messages\": [{\"role\": \"user\", \"content\": \"Create a comprehensive ML document\"}],\n",
    "        \"custom_inputs\": {\"catalog\": CATALOG, \"schema\": SCHEMA, \"model\": model},\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9908063f-d1d4-4d6d-bf43-85e56f4bf7e9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown\n",
    "\n",
    "display(Markdown(result.custom_outputs[\"final_document\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "70b13268-66a5-4308-a1ce-608f58d7a934",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Log the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-03T01:42:35.551887Z",
     "start_time": "2025-03-03T01:42:24.844308Z"
    },
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2e7960d1-ba90-4b55-ae2b-2fd1bdc8a616",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import os\n",
    "from ml_documentation_agent import LLM_ENDPOINT_NAME\n",
    "from mlflow.models.resources import DatabricksFunction, DatabricksServingEndpoint\n",
    "from unitycatalog.ai.langchain.toolkit import UnityCatalogTool\n",
    "\n",
    "resources = [DatabricksServingEndpoint(endpoint_name=LLM_ENDPOINT_NAME)]\n",
    "UC_MODEL_NAME = \"fins_genai.agents.ml_documentation_agent\"\n",
    "os.environ[\"DATABRICKS_API_KEY\"] = dbutils.secrets.get(\"databricks_token_qyu\", \"qyu_rag_sp_token\")\n",
    "\n",
    "with mlflow.start_run():\n",
    "    logged_agent_info = mlflow.pyfunc.log_model(\n",
    "        artifact_path=\"agent\",\n",
    "        python_model=\"ml_documentation_agent.py\",\n",
    "        code_path=[\"model_artifacts_organizer.py\", \"file_management_utils.py\"],\n",
    "        input_example={\n",
    "            \"messages\": [{\"role\": \"user\", \"content\": \"Create a comprehensive ML document\"}],\n",
    "            \"custom_inputs\": {\"catalog\": CATALOG, \"schema\": SCHEMA, \"model\": model}\n",
    "        },\n",
    "        pip_requirements=[\n",
    "            \"mlflow\",\n",
    "            \"langchain\",\n",
    "            \"langgraph<0.3.0\",\n",
    "            \"databricks-langchain\",\n",
    "            \"unitycatalog-langchain[databricks]\",\n",
    "            \"pydantic\",\n",
    "            \"json2html\", \n",
    "            \"markdownify\",\n",
    "            \"nbformat\",\n",
    "            \"nbconvert\"\n",
    "        ],\n",
    "        resources=resources,\n",
    "        registered_model_name=UC_MODEL_NAME\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "632f89cf-966d-4eb4-9870-d48afe6ce449",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Deployment Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fbf1a763-687b-4454-8a31-4548c5844210",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "mlflow.models.predict(\n",
    "    model_uri=f\"runs:/{logged_agent_info.run_id}/agent\",\n",
    "    input_data={\n",
    "            \"messages\": [{\"role\": \"user\", \"content\": \"Create a comprehensive ML document\"}],\n",
    "            \"custom_inputs\": {\"catalog\": CATALOG, \"schema\": SCHEMA, \"model\": model}\n",
    "    },\n",
    "    env_manager=\"uv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a579c57e-ac71-49a0-a325-0327c1c7bc79",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Deploy to an endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8e3019f0-8712-4a27-8a0a-a883362857fb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from databricks import agents\n",
    "agents.deploy(UC_MODEL_NAME, \n",
    "              logged_agent_info.registered_model_version, \n",
    "              environment_vars={\"DATABRICKS_TOKEN\": dbutils.secrets.get(\"databricks_token_qyu\", \"qyu_rag_sp_token\")},\n",
    "              tags = {\"endpointPurpose\": \"ml_documenation_agent\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fc0840ef-4ffd-4ca5-8e4e-2898cf1b7fa7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "ml_documentation_agent_workflow_driver",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
